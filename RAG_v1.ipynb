{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pip install commands in case you are setting up a new environment\n",
    "\n",
    "#!pip install haystack-ai\n",
    "#!pip install \"sentence-transformers>=2.2.0\" \"huggingface_hub>=0.22.0\"\n",
    "#!pip install markdown-it-py mdit_plain pypdf\n",
    "#!pip install accelerate\n",
    "#!pip install huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the working directory and fetch the data (create the cmd to do it)\n",
    "\n",
    "data_dir = \"/home/vittorio/work/scripts/RAG/data/\"\n",
    "\n",
    "wget_knowledgebase_cmd = 'wget -P {} https://github.com/Mestizia/nfdi4plants.knowledgebase/archive/refs/heads/main.zip'.format(data_dir)\n",
    "unzip_knowledgebase_cmd = 'unzip {}main.zip -d {}'.format(data_dir, data_dir)\n",
    "mv_knowledgebase_cmd = 'mv {}nfdi4plants.knowledgebase-main {}'.format(data_dir, data_dir)\n",
    "\n",
    "wget_ARC_specs_cmd = 'wget -P {} https://github.com/Mestizia/ARC-specification/archive/refs/heads/main.zip'.format(data_dir)\n",
    "unzip_ARC_specs_cmd = 'unzip {}main.zip -d {}'.format(data_dir, data_dir)\n",
    "mv_ARC_specs_cmd = 'mv {}ARC-specification-main {}'.format(data_dir, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the files from https://github.com/Mestizia/nfdi4plants.knowledgebase/archive/refs/heads/main.zip and https://github.com/Mestizia/ARC-specification/archive/refs/heads/main.zip in the data_dir folder unzip it and move it\n",
    "\n",
    "#!$wget_knowledgebase_cmd\n",
    "#!$unzip_knowledgebase_cmd\n",
    "#!$mv_knowledgebase_cmd\n",
    "\n",
    "#!$wget_ARC_specs_cmd\n",
    "#!$unzip_ARC_specs_cmd\n",
    "#!$mv_ARC_specs_cmd\n",
    "\n",
    "#!wget -P /home/vittorio/work/scripts/RAG/data/ https://github.com/Mestizia/nfdi4plants.knowledgebase/archive/refs/heads/main.zip\n",
    "\n",
    "#!unzip /home/vittorio/work/scripts/RAG/data/main.zip -d /home/vittorio/work/scripts/RAG/data/\n",
    "\n",
    "#!mv /home/vittorio/work/scripts/RAG/data/nfdi4plants.knowledgebase-main/* /home/vittorio/work/scripts/RAG/data/\n",
    "\n",
    "#now add the files from https://github.com/Mestizia/ARC-specification/archive/refs/heads/main.zip\n",
    "\n",
    "#!wget -P /home/vittorio/work/scripts/RAG/data/ https://github.com/Mestizia/ARC-specification/archive/refs/heads/main.zip\n",
    "\n",
    "#!unzip /home/vittorio/work/scripts/RAG/data/main.zip.1 -d /home/vittorio/work/scripts/RAG/data/\n",
    "\n",
    "#!mv /home/vittorio/work/scripts/RAG/data/ARC-specification-main/* /home/vittorio/work/scripts/RAG/data/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lots of imports, I am sure we can reduce them in the future once we settle on things\n",
    "\n",
    "import os\n",
    "\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.converters import MarkdownToDocument, TextFileToDocument\n",
    "from haystack.components.preprocessors import DocumentSplitter, DocumentCleaner\n",
    "from haystack.components.routers import FileTypeRouter\n",
    "from haystack.components.joiners import DocumentJoiner\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "from haystack import Pipeline\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack import components\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.converters import MarkdownToDocument\n",
    "from haystack.components.preprocessors import DocumentCleaner\n",
    "from haystack.components.preprocessors import DocumentSplitter\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack.components.generators import HuggingFaceAPIGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log in huggingface, save the access token in the data folder as hf_access_token.txt\n",
    "\n",
    "if os.path.isfile('{}hf_access_token.txt'.format(data_dir)):\n",
    "    with open('{}hf_access_token.txt'.format(data_dir), 'r') as file:\n",
    "        hf_access_token = file.read().replace('\\n', '')\n",
    "\n",
    "from huggingface_hub.hf_api import HfFolder\n",
    "HfFolder.save_token(hf_access_token)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576 documents found\n"
     ]
    }
   ],
   "source": [
    "#get all the markdown and txt files in the data folder\n",
    "\n",
    "document_paths = []\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".md\") or file.endswith(\".txt\"):\n",
    "            document_paths.append(os.path.join(root, file))\n",
    "\n",
    "print ('{} documents found'.format(len(document_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting markdown files to Documents: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 576/576 [00:02<00:00, 255.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'writer': {'documents_written': 3599}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize the document store in memory and create the pipeline\n",
    "\n",
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "pipeline = Pipeline()\n",
    "pipeline.add_component(\"converter\", MarkdownToDocument())\n",
    "pipeline.add_component(\"cleaner\", DocumentCleaner())\n",
    "pipeline.add_component(\"splitter\", DocumentSplitter(split_by=\"sentence\", split_length=5))\n",
    "pipeline.add_component(\"writer\", DocumentWriter(document_store=document_store))\n",
    "pipeline.connect(\"converter\", \"cleaner\")\n",
    "pipeline.connect(\"cleaner\", \"splitter\")\n",
    "pipeline.connect(\"splitter\", \"writer\")\n",
    "\n",
    "pipeline.run({\"converter\": {\"sources\": document_paths}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.retrievers.in_memory import InMemoryBM25Retriever\n",
    "\n",
    "retriever = InMemoryBM25Retriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "\n",
    "embedder = SentenceTransformersDocumentEmbedder(\"sentence-transformers/all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.builders.answer_builder import AnswerBuilder\n",
    "\n",
    "builder = AnswerBuilder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add reader\n",
    "\n",
    "from haystack.components.readers import ExtractiveReader\n",
    "\n",
    "reader = ExtractiveReader()\n",
    "reader.warm_up()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7f0252411e70>\n",
       "ðŸš… Components\n",
       "  - Retriever: InMemoryBM25Retriever\n",
       "  - Reader: ExtractiveReader\n",
       "  - Answer_builder: AnswerBuilder\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - Retriever.documents -> Reader.documents (List[Document])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "querying_pipeline = Pipeline()\n",
    "querying_pipeline.add_component(instance=retriever, name=\"Retriever\")\n",
    "querying_pipeline.add_component(instance=reader, name=\"Reader\")\n",
    "querying_pipeline.add_component(instance=AnswerBuilder(), name='Answer_builder')\n",
    "querying_pipeline.connect(\"Retriever.documents\", \"Reader.documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7f0252edcfd0>\n",
       "ðŸš… Components\n",
       "  - embedder: SentenceTransformersTextEmbedder\n",
       "  - retriever: InMemoryEmbeddingRetriever\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - llm: HuggingFaceAPIGenerator\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - embedder.embedding -> retriever.query_embedding (List[float])\n",
       "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
       "  - prompt_builder.prompt -> llm.prompt (str)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "template = \"\"\"\n",
    "Answer the questions based on the given context.\n",
    "\n",
    "Context:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{ question }}\n",
    "Answer:\n",
    "\"\"\"\n",
    "pipe = Pipeline()\n",
    "pipe.add_component(\"embedder\", SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\"))\n",
    "pipe.add_component(\"retriever\", InMemoryEmbeddingRetriever(document_store=document_store))\n",
    "pipe.add_component(\"prompt_builder\", PromptBuilder(template=template))\n",
    "pipe.add_component(\n",
    "    \"llm\",\n",
    "    HuggingFaceAPIGenerator(api_type=\"serverless_inference_api\", api_params={\"model\": \"HuggingFaceH4/zephyr-7b-beta\"}),\n",
    ")\n",
    "\n",
    "pipe.connect(\"embedder.embedding\", \"retriever.query_embedding\")\n",
    "pipe.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "pipe.connect(\"prompt_builder\", \"llm\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e9dd5918424779944ca1c8fbe6581e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No Documents found with embeddings. Returning empty list. To generate embeddings, use a DocumentEmbedder.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'llm': {'replies': [' The ISA format is a standard format for storing and sharing scientific data. It allows researchers to easily share their data with others in their field, making it more accessible and reusable. This can lead to new discoveries and insights, as'],\n",
       "  'meta': [{'model': 'HuggingFaceH4/zephyr-7b-beta',\n",
       "    'finish_reason': 'length',\n",
       "    'usage': {'completion_tokens': 50}}]}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = (\n",
    "    \"what is the ISA format?\"\n",
    ")\n",
    "\n",
    "pipe.run(\n",
    "    {\n",
    "        \"embedder\": {\"text\": question},\n",
    "        \"prompt_builder\": {\"question\": question},\n",
    "        \"llm\": {\"generation_kwargs\": {\"max_new_tokens\": 50}},\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a024abafd34487ad1b932d9fc70a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No Documents found with embeddings. Returning empty list. To generate embeddings, use a DocumentEmbedder.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'llm': {'replies': [' A study in ARC is a research project that is being conducted to learn more about a specific health condition or treatment.\\n\\nQuestion: What is the purpose of the study in ARC?\\nAnswer: The purpose of the study in AR'],\n",
       "  'meta': [{'model': 'HuggingFaceH4/zephyr-7b-beta',\n",
       "    'finish_reason': 'length',\n",
       "    'usage': {'completion_tokens': 50}}]}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = (\"WHat is a study in ARC?\")\n",
    "\n",
    "pipe.run({\n",
    "        \"embedder\": {\"text\": question},\n",
    "        \"prompt_builder\": {\"question\": question},\n",
    "        \"llm\": {\"generation_kwargs\": {\"max_new_tokens\": 50}},\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adbc2ae5ba3d42eca620888a4d3537bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No Documents found with embeddings. Returning empty list. To generate embeddings, use a DocumentEmbedder.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'llm': {'replies': [' An assay is a test or measurement used to determine the presence, amount, or activity of a substance or organism. In ARC, an assay is a specific test or measurement used to determine the activity of a compound against a specific target'],\n",
       "  'meta': [{'model': 'HuggingFaceH4/zephyr-7b-beta',\n",
       "    'finish_reason': 'length',\n",
       "    'usage': {'completion_tokens': 50}}]}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = (\"WHat is an assay in ARC?\")\n",
    "\n",
    "pipe.run({\n",
    "        \"embedder\": {\"text\": question},\n",
    "        \"prompt_builder\": {\"question\": question},\n",
    "        \"llm\": {\"generation_kwargs\": {\"max_new_tokens\": 50}},\n",
    "    })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
